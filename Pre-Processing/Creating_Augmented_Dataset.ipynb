{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "12eaf592-5c74-4a16-b476-b559cffff94a",
   "metadata": {},
   "source": [
    "# Dataset Creation\n",
    "This notebook will create the dataset used to train, validate and test all the models.\n",
    "\n",
    "### Starting Data\n",
    "1. Stripy Fruits/Vegetables (22)\n",
    "2. Stripy Phanotm and Random Objects (12)\n",
    "3. Data from Previous Project (66)\n",
    "\n",
    "### Pipeline\n",
    "1. Use `interactive_cropper.py` to generate a json file with the approximate coordinates of the object inside the entire DCM picture for all images\n",
    "2. Create a `Cropped_Dataset` with all the images at their native resolution\n",
    "3. De-stripe the stripy fruits/vegetables images from the `Cropped_Dataset` using the method from the paper \"Removing Stripes, Scratches, and Curtaining with Non-Recoverable Compressed Sensing\". This is done in a separate Notebook: `Removing_Artifacts.ipynb`.\n",
    "4. Create a dataset for each resolution called `Unaugmented_Final_Dataset` at `2048x2048` size for the following 100 images:\n",
    "   1. The 22 cropped destriped fruits/vegetables\n",
    "   2. The 12 cropped stripy phantoms and random objects\n",
    "   3. The 66 cropped data from the previous project\n",
    "5. Create the final train/val/test splits for the following resolutions: `Res = [512, 1024, 2048]`:\n",
    "   1. Three 15 image folders for test data (`Final_Test_Dataset_<Res>`)\n",
    "   2. Three 340 image folders for the training/validation (`Final_Train_Val_Dataset_<Res>`) using the following transformations:\n",
    "      - Resized Cropping\n",
    "      - Horizontal/Vertical Flipping\n",
    "      - Rotations\n",
    "      - Translations\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e899f46d-16d2-42ca-9d9a-9ac34c70e705",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import time\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import pydicom\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from torchvision import transforms\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import itertools\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a74b9c7-592d-4c29-a9ed-8ebeabc4e431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 100 .dcm files to process.\n",
      "Saving new square crops to: C:/Users/emanu/OneDrive - University of Cape Town/EEE4022S/Data/Cropped_Dataset_2048x2048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating Square Crops: 100%|█████████████████████████████████████████████████████████| 100/100 [00:42<00:00,  2.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Folder with cropped images created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Point this to the folder with your ORIGINAL, full-size images.\n",
    "DICOM_FOLDER = 'C:/Users/emanu/OneDrive - University of Cape Town/EEE4022S/LODOX_Scans' \n",
    "\n",
    "# Point this to the JSON file created by your interactive_cropper.py.\n",
    "COORDINATES_FILE = 'cropping_coordinates.json'\n",
    "\n",
    "# A new folder where the unpadded, square images will be saved.\n",
    "DESTINATION_FOLDER = 'C:/Users/emanu/OneDrive - University of Cape Town/EEE4022S/Data/Cropped_Dataset_2048x2048'\n",
    "\n",
    "SIZE = 2048\n",
    "# --------------------\n",
    "\n",
    "os.makedirs(DESTINATION_FOLDER, exist_ok=True)\n",
    "\n",
    "def crop_to_square(image, start_x, start_y, end_x, end_y):\n",
    "    \"\"\"\n",
    "    Crops an image to a square region based on a bounding box, without adding padding.\n",
    "\n",
    "    Args:\n",
    "        image (PIL.Image): The original image.\n",
    "        start_x, start_y, end_x, end_y (int): Bounding box coordinates.\n",
    "\n",
    "    Returns:\n",
    "        PIL.Image: The squarely cropped image.\n",
    "    \"\"\"\n",
    "    # Calculate the width and height of the bounding box.\n",
    "    box_width = end_x - start_x\n",
    "    box_height = end_y - start_y\n",
    "    \n",
    "    # Find the center of the bounding box.\n",
    "    center_x = start_x + box_width // 2\n",
    "    center_y = start_y + box_height // 2\n",
    "    \n",
    "    # Determine the half-length of the new square's side (using the longest side of the box).\n",
    "    half_side = max(box_width, box_height) // 2\n",
    "    \n",
    "    # Calculate the new square's coordinates.\n",
    "    left = center_x - half_side\n",
    "    top = center_y - half_side\n",
    "    right = center_x + half_side\n",
    "    bottom = center_y + half_side\n",
    "    \n",
    "    # Crop the image to the new square dimensions.\n",
    "    cropped_image = image.crop((left, top, right, bottom))\n",
    "    \n",
    "    return cropped_image\n",
    "\n",
    "# Load the cropping coordinates from your JSON file.\n",
    "with open(COORDINATES_FILE, 'r') as f:\n",
    "    cropping_coordinates = json.load(f)\n",
    "\n",
    "all_files = [f for f in os.listdir(DICOM_FOLDER) if f.lower().endswith('.dcm')]\n",
    "print(f\"Found {len(all_files)} .dcm files to process.\")\n",
    "print(f\"Saving new square crops to: {DESTINATION_FOLDER}\")\n",
    "\n",
    "# Process each image.\n",
    "for filename in tqdm(all_files, desc=\"Creating Square Crops\"):\n",
    "    source_path = os.path.join(DICOM_FOLDER, filename)\n",
    "    \n",
    "    # Check if coordinates exist for this file before processing.\n",
    "    if filename in cropping_coordinates:\n",
    "        coords = cropping_coordinates[filename]\n",
    "        dicom_file = pydicom.dcmread(source_path)\n",
    "        pixel_array = dicom_file.pixel_array.astype(np.float32)\n",
    "        image_255 = ((pixel_array - pixel_array.min()) / (pixel_array.max() - pixel_array.min()) * 255).astype(np.uint8)\n",
    "        img = Image.fromarray(image_255)\n",
    "\n",
    "        square_crop = crop_to_square(img, \n",
    "                                     coords['start_x'], coords['start_y'],\n",
    "                                     coords['end_x'], coords['end_y'])\n",
    "        final_image = square_crop.resize((SIZE, SIZE), Image.Resampling.LANCZOS)    \n",
    "        base_name = os.path.splitext(filename)[0]\n",
    "        save_path = os.path.join(DESTINATION_FOLDER, f\"{base_name}.png\")\n",
    "        final_image.save(save_path)\n",
    "        # square_crop.save(save_path) # for full res images\n",
    "\n",
    "    else:\n",
    "        print(f\"Warning: No coordinates found for {filename} in {COORDINATES_FILE}. Skipping file.\")\n",
    "\n",
    "print(\"\\nFolder with cropped images created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9812b21-8d6a-4e2c-9aa4-aad615108fb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/Val folder for 512x512: C:/Users/emanu/OneDrive - University of Cape Town/EEE4022S/Data/Final/Train_Val_512x512\n",
      "Test folder for 512x512: C:/Users/emanu/OneDrive - University of Cape Town/EEE4022S/Data/Final/Test_512x512\n",
      "Train/Val folder for 1024x1024: C:/Users/emanu/OneDrive - University of Cape Town/EEE4022S/Data/Final/Train_Val_1024x1024\n",
      "Test folder for 1024x1024: C:/Users/emanu/OneDrive - University of Cape Town/EEE4022S/Data/Final/Test_1024x1024\n",
      "Train/Val folder for 2048x2048: C:/Users/emanu/OneDrive - University of Cape Town/EEE4022S/Data/Final/Train_Val_2048x2048\n",
      "Test folder for 2048x2048: C:/Users/emanu/OneDrive - University of Cape Town/EEE4022S/Data/Final/Test_2048x2048\n",
      "Total source images: 100\n",
      "Splitting into:\n",
      "  - Test set: 15 images\n",
      "  - Train/Val set for augmentation: 85 images\n",
      "\n",
      "Creating multi-resolution test sets...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating Test Sets: 100%|██████████████████████████████████████████████████████████████| 15/15 [00:06<00:00,  2.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test sets created successfully.\n",
      "\n",
      "Generating 4 augmented versions per image for each resolution set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Augmenting Train/Val Sets: 100%|███████████████████████████████████████████████████████| 85/85 [02:21<00:00,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Multi-Resolution Offline Augmentation Complete ---\n",
      "Total images in 512x512 train/val set: 340\n",
      "Total images in 1024x1024 train/val set: 340\n",
      "Total images in 2048x2048 train/val set: 340\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# --- Configuration ---\n",
    "\n",
    "# 1. Point this to the folder containing your 34 clean, square, unpadded .png images from before\n",
    "SOURCE_IMAGES_DIR = 'C:/Users/emanu/OneDrive - University of Cape Town/EEE4022S/Data/Unaugmented_Full_Dataset_2048x2048'\n",
    "\n",
    "# 3. --- Define a list of all the resolutions you want to generate ---\n",
    "TARGET_SIZES = [512, 1024, 2048]\n",
    "\n",
    "# 4. Define the destination directories.\n",
    "BASE_TRAIN_VAL_DIR = 'C:/Users/emanu/OneDrive - University of Cape Town/EEE4022S/Data/Final/Train_Val'\n",
    "BASE_TEST_DIR = 'C:/Users/emanu/OneDrive - University of Cape Town/EEE4022S/Data/Final/Test'\n",
    "\n",
    "# 5. Set the parameters for the split and augmentation.\n",
    "TEST_SPLIT_RATIO = 0.15\n",
    "TARGET_TRAIN_VAL_SIZE_PER_SET = 300 # The approximate number of images you want in your final train/val set.\n",
    "\n",
    "# --------------------\n",
    "\n",
    "# --- Create destination directories if they don't exist ---\n",
    "# os.makedirs(BASETRAIN_VAL_DIR, exist_ok=True)\n",
    "# os.makedirs(TEST_DIR, exist_ok=True)\n",
    "train_val_folders = {}\n",
    "test_folders = {}\n",
    "for size in TARGET_SIZES:\n",
    "    # Create and store paths for train/val folders\n",
    "    train_val_path = f\"{BASE_TRAIN_VAL_DIR}_{size}x{size}\"\n",
    "    os.makedirs(train_val_path, exist_ok=True)\n",
    "    train_val_folders[size] = train_val_path\n",
    "    \n",
    "    # Create and store paths for test folders\n",
    "    test_path = f\"{BASE_TEST_DIR}_{size}x{size}\"\n",
    "    os.makedirs(test_path, exist_ok=True)\n",
    "    test_folders[size] = test_path\n",
    "    \n",
    "    print(f\"Train/Val folder for {size}x{size}: {train_val_path}\")\n",
    "    print(f\"Test folder for {size}x{size}: {test_path}\")\n",
    "# ------------------------------------\n",
    "\n",
    "\n",
    "# --- 1. Split the source files ---\n",
    "all_files = [f for f in os.listdir(SOURCE_IMAGES_DIR) if f.lower().endswith('.png')]\n",
    "random.shuffle(all_files) # Shuffle the files for a random split.\n",
    "\n",
    "test_set_size = int(len(all_files) * TEST_SPLIT_RATIO)\n",
    "test_files = all_files[:test_set_size]\n",
    "train_val_files = all_files[test_set_size:]\n",
    "\n",
    "print(f\"Total source images: {len(all_files)}\")\n",
    "print(f\"Splitting into:\")\n",
    "print(f\"  - Test set: {len(test_files)} images\")\n",
    "print(f\"  - Train/Val set for augmentation: {len(train_val_files)} images\")\n",
    "\n",
    "\n",
    "# --- 2. Create the Multi-Resolution Test Sets ---\n",
    "print(f\"\\nCreating multi-resolution test sets...\")\n",
    "for filename in tqdm(test_files, desc=\"Creating Test Sets\"):\n",
    "    source_path = os.path.join(SOURCE_IMAGES_DIR, filename)\n",
    "    image = Image.open(source_path)\n",
    "    \n",
    "    # Loop through target sizes, resize, and save to the correct test folder.\n",
    "    for size in TARGET_SIZES:\n",
    "        resized_image = image.resize((size, size), Image.Resampling.LANCZOS)\n",
    "        destination_path = os.path.join(test_folders[size], filename)\n",
    "        resized_image.save(destination_path)\n",
    "print(\"Test sets created successfully.\")\n",
    "\n",
    "# --- 3. Create the Multi-Resolution Augmented Train/Val Sets ---\n",
    "\n",
    "# Define the set of augmentations.\n",
    "augmentation_transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(size=(2048, 2048), scale=(0.3, 1.0), ratio=(1.0, 1.0)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomVerticalFlip(p=0.5),\n",
    "    transforms.RandomApply([transforms.RandomRotation(degrees=20)], p=0.7),\n",
    "    transforms.RandomApply([transforms.RandomAffine(degrees=0, translate=(0.15, 0.15))], p=0.5),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "])\n",
    "\n",
    "if len(train_val_files) > 0:\n",
    "    num_versions_per_image = int(np.ceil(TARGET_TRAIN_VAL_SIZE_PER_SET / len(train_val_files)))\n",
    "    print(f\"\\nGenerating {num_versions_per_image} augmented versions per image for each resolution set...\")\n",
    "\n",
    "    for filename in tqdm(train_val_files, desc=\"Augmenting Train/Val Sets\"):\n",
    "        source_path = os.path.join(SOURCE_IMAGES_DIR, filename)\n",
    "        original_image = Image.open(source_path).convert('L')\n",
    "        base_name, extension = os.path.splitext(filename)\n",
    "\n",
    "        for i in range(num_versions_per_image):\n",
    "            # Apply the random transformations to the original image.\n",
    "            augmented_image = augmentation_transform(original_image)\n",
    "            \n",
    "            new_filename = f\"{base_name}_aug_{i}{extension}\"\n",
    "\n",
    "            # Now, resize and save this one augmented image to all target resolution folders.\n",
    "            for size in TARGET_SIZES:\n",
    "                # Resize the augmented image to the current target size.\n",
    "                final_image = augmented_image.resize((size, size), Image.Resampling.LANCZOS)\n",
    "                \n",
    "                # Save to the correct destination folder.\n",
    "                destination_path = os.path.join(train_val_folders[size], new_filename)\n",
    "                final_image.save(destination_path)\n",
    "else:\n",
    "    print(\"\\nNo files in the training/validation set to augment.\")\n",
    "\n",
    "print(\"\\n--- Multi-Resolution Offline Augmentation Complete ---\")\n",
    "for size in TARGET_SIZES:\n",
    "    print(f\"Total images in {size}x{size} train/val set: {len(os.listdir(train_val_folders[size]))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba46de21-9b86-4c0b-87d0-33b5cd59f710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created output directory: C:/Users/emanu/OneDrive - University of Cape Town/EEE4022S/Data/DIP_Destripe_In\n",
      "Found 3 images to resize.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "200cacd3cefd423d9341f8bb3835c921",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resizing Images:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Image resizing complete! Resized images are saved in: C:/Users/emanu/OneDrive - University of Cape Town/EEE4022S/Data/DIP_Destripe_In\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from tqdm.notebook import tqdm # Use tqdm.notebook for a nice progress bar in Jupyter\n",
    "\n",
    "# --- 1. Configuration: SET YOUR FOLDERS HERE ---\n",
    "INPUT_FOLDER = 'C:/Users/emanu/OneDrive - University of Cape Town/EEE4022S/Data/Final/NRCS_In'\n",
    "OUTPUT_FOLDER = 'C:/Users/emanu/OneDrive - University of Cape Town/EEE4022S/Data/DIP_Destripe_In'\n",
    "TARGET_RESOLUTION = (512, 512)\n",
    "\n",
    "# --- 2. Create the output directory if it doesn't exist ---\n",
    "if not os.path.exists(OUTPUT_FOLDER):\n",
    "    os.makedirs(OUTPUT_FOLDER)\n",
    "    print(f\"Created output directory: {OUTPUT_FOLDER}\")\n",
    "\n",
    "# --- 3. Find and filter all image files ---\n",
    "files = os.listdir(INPUT_FOLDER)\n",
    "image_files = [f for f in files if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif'))]\n",
    "\n",
    "if not image_files:\n",
    "    print(f\"No images found in '{INPUT_FOLDER}'. Please check the path.\")\n",
    "else:\n",
    "    print(f\"Found {len(image_files)} images to resize.\")\n",
    "\n",
    "    # --- 4. Loop through images, resize, and save ---\n",
    "    for filename in tqdm(image_files, desc=\"Resizing Images\"):\n",
    "        try:\n",
    "            # Construct full file paths\n",
    "            input_path = os.path.join(INPUT_FOLDER, filename)\n",
    "            output_path = os.path.join(OUTPUT_FOLDER, filename)\n",
    "\n",
    "            # Open, resize, and save the image\n",
    "            with Image.open(input_path) as img:\n",
    "                # Image.Resampling.LANCZOS is a high-quality filter for downscaling\n",
    "                resized_img = img.resize(TARGET_RESOLUTION, Image.Resampling.LANCZOS)\n",
    "                resized_img.save(output_path)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Could not process {filename}. Reason: {e}\")\n",
    "\n",
    "    print(f\"\\nImage resizing complete! Resized images are saved in: {OUTPUT_FOLDER}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04ccf41-f45e-4591-917d-982f5236899c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (n2s)",
   "language": "python",
   "name": "n2s"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
